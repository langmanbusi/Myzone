### My implementation: 

##### Set export folder

```bash
export PREPROCESSED_DATASETS_FOLDER=/data2/wuyuhui
```

##### train

```bash
CUDA_VISIBLE_DEVICES=0 python train.py --config configs/train_e2depth_si_grad_loss_statenet_ergb.json
```

##### train with ckpt
```
CUDA_VISIBLE_DEVICES=0 python train.py --config configs/train_e2depth_si_grad_loss_statenet_ergb.json --initial_checkpoint /data2/wuyuhui/mvsec/ckpt/sim2real_20/model_best.pth.tar
```

##### test_S

```bash
CUDA_VISIBLE_DEVICES=0 python test.py --path_to_model /data2/wuyuhui/Eventscape/ramnet_sim.pth.tar --output_path /data2/wuyuhui/Eventscape/e2depth_evaluation/test_s --data_folder /data2/wuyuhui/Eventscape/Town05_test/Town05/ --config configs/train_e2depth_si_grad_loss_statenet_ergb.json
```

##### test_S\_R

```bash
CUDA_VISIBLE_DEVICES=0 python test.py --path_to_model /data2/wuyuhui/mvsec/ckpt/sim2real_20/model_best.pth.tar --output_path /data2/wuyuhui/mvsec/e2depth_evaluation/S2Rday1_20epoch_test --data_folder /data2/wuyuhui/mvsec/test1 --config configs/train_e2depth_si_grad_loss_statenet_ergb.json
```

##### evaluation_S

```bash
CUDA_VISIBLE_DEVICES=0 python evaluation.py --target_dataset /data2/wuyuhui/Eventscape/e2depth_evaluation/test_s/ground_truth/npy/depth_event4/ --predictions_dataset /data2/wuyuhui/Eventscape/e2depth_evaluation/test_s/npy/events4/ --clip_distance 1000 --reg_factor 5.70378
```

##### evaluation_S\_R

```bash
CUDA_VISIBLE_DEVICES=0 python evaluation.py --target_dataset /data2/wuyuhui/mvsec/e2depth_evaluation/S2Rday1_20epoch_test/ground_truth/npy/depth/ --predictions_dataset /data2/wuyuhui/mvsec/e2depth_evaluation/S2Rday1_20epoch_test/npy/events_last/ --clip_distance 80 --reg_factor 3.70378
```

dataset的`__getitem__`返回形状：

首先获取 `item` ：

* train：
	* 首先返回`item(events0 : , events1 : , event2 : , events3 : , events4 : , depth_events0 : , depth_events1 : , depth_events2 : , depth_events3 : , depth_events4 : , image : )`
	* 再返回`sequence`，根据`sequence_length=5`，在sequence中`append(item)`，最终包含5个`item`

* test：item中除了train中的那些部分之外，还有`semantic_seg_0,1,2,3,4` : ，读取的是`semantic/data`中的`gt_labelIds.png`，但是没有用

结果：absolute relative depth error, mean absolute depth error (10m, 20m, 30m)

#### Eventscape数据集格式：

* Town01\_03\_train
	
	* sequence\_abc\_town0x
	* vehicle_data
	* semantic
	* rgb
		* data
			* 0x\_abc\_0yyy\_image.png
			* timestamps.txt
	* events
		* voxels
			* 0x\_abc\_0yyy\_voxel.npy
			* timestamps.txt
			* boundary\_timestamps.txt
		* frames
		* data
	* depth
		* frames
		* data
			* 0x\_abc\_0yyy\_depth.npy

#### MVSEC数据集格式

已下载的MVSEC sequence：`mvsec_outdoor_day2, mvsec_outdoor_day1`，day1的数据集没有split成三个集，day2的数据已经split了。

* mvsec\_outdoor\_day2
	* train (8523 samples)
		* rgb
			* visensor
			* davis
				* frame\_000000yyyy.png
				* timestamps.txt
		* events
			* voxels
				* event\_tensor\_000000yyyy.npy
				* timestamps.txt
		* depth
			* frames
			* data
				* depth\_000000yyyy.npy
				* timestamps.txt
	* validation (1826 samples)
	* test (1826 samples)

### 2022/1/12

实验sim2real，报错，检查数据结构，发现是配置错误

sim2real在`mvsec_day2`上跑了20个epoch，sim在`EventScape`上跑了100个epoch。

sim2real又跑了之后效果变好一些，继续尝试跑200个epoch。


### 2022/1/11

因为复现结果不正常，还是要把程序看懂再做分析。

结果和crop大小无关。

训练一下ckpt，看model和trainer的逻辑

		
### 2022/1/10

看代码，用outdoorday1和outdoorday2的数据集进行test，并看model的逻辑。

遇到问题：

```
 File "/home/wuyuhui/wyh/RAM_MVSEC/RAM_Net/data_loader/dataset.py", line 248, in __getitem__
    (frame_idx, frame_timestamp) = first_element_greater_than(self.stamps, event_timestamp)
  File "/home/wuyuhui/wyh/RAM_MVSEC/RAM_Net/utils/util.py", line 22, in first_element_greater_than
    if abs(values[i] - req_value) > 0.01:
IndexError: index 5126 is out of bounds for axis 0 with size 5126
```

看了看代码，解决。

```
# Find the index of the first frame whose timestamp is >= event timestamp
(frame_idx, frame_timestamp) = first_element_greater_than(self.stamps, event_timestamp)

def first_element_greater_than(values, req_value):
    """Returns the pair (i, values[i]) such that i is the minimum value that satisfies values[i] >= req_value.
    Returns (-1, None) if there is no such i. Note: this function assumes that values is a sorted array!"""
    # 将event的timestamp插入depth的timestamp列表中时，应该插入的索引位置，value为depth的ts，req_value为depth的ts
    # shape(value) = (5126, 2), req_value = eventstamp[5125]时，得到i = 5126，超出索引。
    i = np.searchsorted(values, req_value)
    if abs(values[i] - req_value) > 0.01:
        # for mvsec, depth timestamps aren't always bigger than the event timestamps. This can lead to choosing a
        # value that that is too large, which is fixed here.
        i = i - 1
    val = values[i] if i < len(values) else None
    return (i, val)
```

文中有一句描述：

	For EventScape we choose α = 5.7 and Dmax = 1000 m whereas for MVSEC we choose α = 3.7 and Dmax = 80 m.
	
获得了day1和day2的结果，文中只有day1的结果，对比之后感觉不太对，再试试night1。

* day1: S, S->R
* night1: S, S->R

s2r的ckpt使用5.7和1000效果很差，符合预期。

* 明天尝试s2r在EventScape上的效果，继续训练一下看看效果，多看文章，泛读。


### 2022/1/8

尝试用mvsec的day1做测试集失败，报错。

看了一下相关的文章，E2Depth。发现E2Depth这篇文章的项目主页有数据集，包括

```bash
mvsec_outdoor_day2, mvsec_outdoor_day1, mvsec_outdoor_night1, mvsec_outdoor_night2, mvsec_outdoor_night3
```

### 2022/1/7

看了一下ET-Net的代码，没有train，暂时无法复现，但是model部分还算完整，可以借鉴。

主要还是在看RAMNet的代码，使用MVSEC的dataset和Eventscape的dataset还不一样，很复杂，需要再查资料看。查看了一下hdf5文件中的格式。


### 2022/1/6 

实现了生成所有的voxel文件，test集106.71g，val集91.89g，train集116g -> 502.62g

运行了一次test和evaluation，`_abs_rel_diff : 0.197506`，文中为0.198

